{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=3,6\n",
    "\n",
    "import os\n",
    "import logging\n",
    "\n",
    "os.environ.pop(\"HF_HUB_OFFLINE\", None)\n",
    "logging.getLogger().setLevel(logging.ERROR)  # or logging.CRITICAL\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "from absl import app, flags\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils import *\n",
    "import utils\n",
    "try:\n",
    "    from vllm import LLM, SamplingParams\n",
    "    import ray\n",
    "except ImportError:\n",
    "    pass\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import torch\n",
    "def get_freest_cuda_device():\n",
    "    result = subprocess.run(\n",
    "        ['nvidia-smi', '--query-gpu=memory.free', '--format=csv,nounits,noheader'],\n",
    "        stdout=subprocess.PIPE, encoding='utf-8')\n",
    "    memory_free = [int(x) for x in result.stdout.strip().split('\\n')]\n",
    "    return memory_free.index(max(memory_free))\n",
    "\n",
    "best_gpu = get_freest_cuda_device()\n",
    "device = torch.device(f\"cuda:{best_gpu}\")\n",
    "print(f\"Using GPU: {device}\")\n",
    "# %env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.abspath('../openai.txt'), 'r') as f:\n",
    "    utils.client = OpenAI(api_key=f.read().rstrip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Explicitly unset all offline-related env vars\n",
    "os.environ.pop(\"HF_HUB_OFFLINE\", None)\n",
    "os.environ.pop(\"TRANSFORMERS_OFFLINE\", None)\n",
    "os.environ[\"HF_HUB_OFFLINE\"] = \"0\"\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"0\"\n",
    "\n",
    "with open(\"../token.txt\", \"r\") as f:\n",
    "    token = f.read().strip()\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(text):\n",
    "    \"\"\"\n",
    "    Counts the number of words in the given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): Input text.\n",
    "\n",
    "    Returns:\n",
    "        int: Number of words in the text.\n",
    "    \"\"\"\n",
    "    if text!=None:\n",
    "        words = text.split()\n",
    "        return len(words)\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personas = [\n",
    "  # Elementary\n",
    "  {\n",
    "    \"grade_level\": \"elementary school\",\n",
    "    \"description\": (\n",
    "      \"As an elementary school student with a Narrative learning style, I absorb new concepts best when they’re told as engaging mini-stories. \"\n",
    "      \"In dialogue, I ask for short anecdotes that turn any abstract idea into a vivid tale with characters, a clear sequence, and an emotional hook. \"\n",
    "      \"Stories help me remember causal links and keep details alive in my mind.\"\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"grade_level\": \"elementary school\",\n",
    "    \"description\": (\n",
    "      \"As an elementary school student with a Kinesthetic learning style, I understand ideas by imagining myself performing them. \"\n",
    "      \"In conversation, I ask you to guide me through a pretend play-through—verbally walking me step by step as if I’m enacting a simple experiment or physical process. \"\n",
    "      \"This imagined movement helps me anchor concepts in ‘muscle memory’ even though we’re only talking.\"\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"grade_level\": \"elementary school\",\n",
    "    \"description\": (\n",
    "      \"As an elementary school student with a Naturalistic learning style, I connect best when content is tied to the natural world through vivid imagery. \"\n",
    "      \"In dialogue, I ask you to compare topics—like atomic structure—to things I observe outdoors, such as tree rings or bird migrations. \"\n",
    "      \"These verbal nature metaphors make new information feel familiar and alive.\"\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"grade_level\": \"elementary school\",\n",
    "    \"description\": (\n",
    "      \"As an elementary school student with an Experiential learning style, I learn by mentally simulating real-world tasks. \"\n",
    "      \"In conversation, I ask you to walk me through building or testing something—describing each step as if I’m doing it. \"\n",
    "      \"That imagined ‘doing’ makes concepts concrete, even though we remain in chat.\"\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"grade_level\": \"elementary school\",\n",
    "    \"description\": (\n",
    "      \"As an elementary school student with a Creative-Divergent learning style, I thrive on brainstorming multiple possibilities. \"\n",
    "      \"In dialogue, I propose ‘what if’ scenarios—like alternative endings or playful twists on a concept—and talk through each idea. \"\n",
    "      \"Verbal brainstorming reveals fresh patterns and sparks my imagination.\"\n",
    "    )\n",
    "  },\n",
    "\n",
    "  # Middle\n",
    "  {\n",
    "    \"grade_level\": \"middle school\",\n",
    "    \"description\": (\n",
    "      \"As a middle school student with a Visual-Spatial learning style, I think in mental images and diagrams. \"\n",
    "      \"In conversation, I ask you to ‘paint’ word-pictures—step-by-step descriptions of scenes or flows—so I can build a clear mental map. \"\n",
    "      \"That verbal imagery helps me organize information spatially in my mind.\"\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"grade_level\": \"middle school\",\n",
    "    \"description\": (\n",
    "      \"As a middle school student with an Auditory learning style, I internalize knowledge through sound and speech. \"\n",
    "      \"In dialogue, I ask you to restate key points in different rhythms or tones, and I repeat them back to reinforce my memory. \"\n",
    "      \"Hearing and echoing concepts in conversation makes them stick.\"\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"grade_level\": \"middle school\",\n",
    "    \"description\": (\n",
    "      \"As a middle school student with a Logical-Mathematical learning style, I seek numerical patterns and rule-based reasoning. \"\n",
    "      \"In dialogue, I pose ‘what-if’ questions—‘If X doubles, what changes?’—and we talk through each scenario using simple calculations. \"\n",
    "      \"Quantitative hypotheticals build my systematic understanding.\"\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"grade_level\": \"middle school\",\n",
    "    \"description\": (\n",
    "      \"As a middle school student with an Analytical-Argument learning style, I dissect arguments and causal chains. \"\n",
    "      \"In conversation, I ask targeted ‘why’ and ‘how’ questions about each step, construct mini flow-charts aloud, and verify the logic with you. \"\n",
    "      \"This structured debate hones my precision in reasoning.\"\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"grade_level\": \"middle school\",\n",
    "    \"description\": (\n",
    "      \"As a middle school student with a Verbal-Linguistic learning style, I learn through rich language and writing. \"\n",
    "      \"In dialogue, I request carefully worded definitions, paraphrase ideas in my own words, and craft mnemonic rhymes on the spot. \"\n",
    "      \"Talking through ideas in text-like sentences and playing with words helps me remember precisely.\"\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"grade_level\": \"middle school\",\n",
    "    \"description\": (\n",
    "      \"As a middle school student with a Technology-Enhanced learning style, I thrive on conversational simulations of digital tools. \"\n",
    "      \"In dialogue, I ask you to describe how a virtual model might respond as we adjust parameters, or to role-play a flashcard quiz verbally. \"\n",
    "      \"These imagined tech interactions keep me engaged without leaving our chat.\"\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"grade_level\": \"middle school\",\n",
    "    \"description\": (\n",
    "      \"As a middle school student with a Mnemonic learning style, I anchor facts with memory aids. \"\n",
    "      \"In dialogue, I ask for catchy acronyms, rhymes, or vivid mental images—then recite them back. \"\n",
    "      \"That verbal encoding makes complex lists or steps easy to retrieve.\"\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"grade_level\": \"middle school\",\n",
    "    \"description\": (\n",
    "      \"As a middle school student with an Emotional learning style, I connect through feelings and empathy. \"\n",
    "      \"In conversation, I ask you to frame concepts in human-centered narratives that highlight emotional stakes. \"\n",
    "      \"These emotionally rich verbal stories make ideas memorable and meaningful.\"\n",
    "    )\n",
    "  },\n",
    "\n",
    "  # High School\n",
    "  {\n",
    "    \"grade_level\": \"high school\",\n",
    "    \"description\": (\n",
    "      \"As a high school student with a Collaborative learning style, I excel in multi-voice discussions. \"\n",
    "      \"In dialogue, I invite hypothetical peers into our chat—debating viewpoints, role-playing characters, or comparing interpretations. \"\n",
    "      \"That social exchange refines my understanding.\"\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"grade_level\": \"high school\",\n",
    "    \"description\": (\n",
    "      \"As a high school student with an Interpersonal learning style, I flourish in one-on-one exchanges. \"\n",
    "      \"In conversation, I engage deeply with a single partner—asking questions, providing feedback, and co-constructing ideas through back-and-forth talk.\"\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"grade_level\": \"high school\",\n",
    "    \"description\": (\n",
    "      \"As a high school student with a Reflective learning style, I pause and summarize before responding. \"\n",
    "      \"In dialogue, I restate points in my own words, journal key ideas mentally, and then ask precise follow-ups. \"\n",
    "      \"This verbal reflection clarifies gaps and deepens comprehension.\"\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"grade_level\": \"high school\",\n",
    "    \"description\": (\n",
    "      \"As a high school student with a Metaphorical learning style, I anchor concepts in analogies. \"\n",
    "      \"In dialogue, I ask you to compare subjects to familiar scenarios—‘It’s like X because…’—and we talk through how well the metaphor holds. \"\n",
    "      \"Testing analogies verbally helps me translate abstract ideas into relatable terms.\"\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"grade_level\": \"high school\",\n",
    "    \"description\": (\n",
    "      \"As a high school student with an Intrapersonal learning style, I connect content to my own values. \"\n",
    "      \"In dialogue, I ask how topics relate to my goals or experiences and share personal reflections aloud. \"\n",
    "      \"That self-referential talk makes learning relevant and motivating.\"\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"grade_level\": \"high school\",\n",
    "    \"description\": (\n",
    "      \"As a high school student with a Problem-Based learning style, I tackle hypothetical real-world scenarios in talk. \"\n",
    "      \"In dialogue, I propose case studies—like designing a sustainable system—and we walk through each decision together. \"\n",
    "      \"Verbal scenario-based reasoning shows me practical applications of theory.\"\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"grade_level\": \"high school\",\n",
    "    \"description\": (\n",
    "      \"As a high school student with a Trial-and-Error learning style, I learn by mentally testing ideas. \"\n",
    "      \"In dialogue, I suggest imagined experiments—‘Let’s tweak this variable and see what happens’—and we discuss the outcomes. \"\n",
    "      \"Using mistakes as discussion points builds discovery-based understanding.\"\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"grade_level\": \"high school\",\n",
    "    \"description\": (\n",
    "      \"As a high school student with a Conceptual learning style, I focus on verbal mapping of frameworks. \"\n",
    "      \"In dialogue, I request thematic overviews—described step by step—and we discuss how each piece fits into the big picture. \"\n",
    "      \"Building mental models in talk deepens my flexible understanding.\"\n",
    "    )\n",
    "  },\n",
    "\n",
    "  # College\n",
    "  {\n",
    "    \"grade_level\": \"college\",\n",
    "    \"description\": (\n",
    "      \"As a college student with a Theoretical learning style, I probe abstract frameworks in conversation. \"\n",
    "      \"In dialogue, I challenge you to trace ideas back to their assumptions, compare theoretical models, and debate implications. \"\n",
    "      \"This verbal inquiry drives deep synthesis.\"\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"grade_level\": \"college\",\n",
    "    \"description\": (\n",
    "      \"As a college student with a Research-Oriented learning style, I learn by interrogating studies in chat. \"\n",
    "      \"In conversation, I ask for summaries of current research, discuss methods and controls, and role-play peer-review feedback. \"\n",
    "      \"Critically evaluating evidence through talk builds an evidence-based grasp.\"\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"grade_level\": \"college\",\n",
    "    \"description\": (\n",
    "      \"As a college student with an Integrative learning style, I weave ideas together verbally. \"\n",
    "      \"In conversation, I ask for cross-topic syntheses—connecting historical, artistic, and scientific themes—and discuss their intersections step by step. \"\n",
    "      \"This systems-level perspective helps me approach complex questions creatively.\"\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"grade_level\": \"college\",\n",
    "    \"description\": (\n",
    "      \"As a college student with a Structured learning style, I excel on verbal outlines and modules. \"\n",
    "      \"In dialogue, I ask for hierarchical breakdowns—numbered lists, staged explanations, and schematic overviews—before diving into details.\"\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"grade_level\": \"college\",\n",
    "    \"description\": (\n",
    "      \"As a college student with a Solitary learning style, I prefer self-guided dialog prompts. \"\n",
    "      \"In our conversation, I request personalized questions and silent think-time before sharing my conclusions, using chat as a safe space for independent reflection.\"\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"grade_level\": \"college\",\n",
    "    \"description\": (\n",
    "      \"As a college student with an Adaptive learning style, I shift strategies based on what works. \"\n",
    "      \"In dialogue, I monitor which verbal approaches—stories, logic puzzles, analogies—help me most and ask to switch accordingly. \"\n",
    "      \"This dynamic, metacognitive talk ensures I absorb concepts through the most effective modality.\"\n",
    "    )\n",
    "  }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "config_role = {\n",
    "    \"agent1_role\": \"Teacher\",\n",
    "    \"agent2_role\": \"Student\",\n",
    "    \"agent1_prompt\": \"You are a teacher whose goal is to guide a student through learning about %SUBJECT%. You have a preferred way to teach the student. The student is in %ROLE% so make sure to teach them at their level. \",\n",
    "    \"agent2_prompt\": \"You are a student in %ROLE% in conversation with a teacher who will teach you %SUBJECT%. You like to learn in the following way:\\n%SPEAKER_BACKSTORY%.\\nMake sure to not only ask questions but also demonstrate your knowledge.\",\n",
    "    'reminder_prompt': \"Keep your response very brief — 2 sentences or less. Do NOT repeat anything you've already said.\\n\",\n",
    "    'eval_prompts': {\n",
    "    'prompt_consistency': \"\"\"You are evaluating whether the following utterance by %SPEAKER_ROLE% is consistent with their given background. Answer YES if the line directly contradicts any part of the background—this includes contradictions in facts, behavior, beliefs, emotional stance, or conversational strategy. Answer NO if the line introduces new details, but those details are **plausibly aligned** with the background. Be strict and literal in your evaluation: if the line violates the persona’s stated traits (e.g., avoids vulnerability, keeps answers short, avoids discussing personal topics), mark it as a contradiction even if the violation is subtle. Background for %SPEAKER_ROLE%: %SPEAKER_BACKSTORY% Line spoken by %SPEAKER_ROLE%: %SPEAKER_LINE%  Answer YES if the line contradicts the background, and NO if it does not. Then, explain your answer in one sentence. Be precise and avoid vague justification.\"\"\"}}\n",
    "\n",
    "os.makedirs(\"education\", exist_ok=True)\n",
    "with open(\"education/config_education.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(config_role, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./config/education/personas_education_master.json', 'r') as f:\n",
    "    conversation_prompts = json.load(f)\n",
    "conversation_prompts[0]['background_info'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list = []\n",
    "for convo_prompt in conversation_prompts:\n",
    "    topic_prompt = convo_prompt[\"background_info\"][\"topic\"]\n",
    "    topic_list.append(topic_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llms = [\"Llama-3.1-8B-Instruct\", \"gpt-4o-mini\", \"Qwen2.5-3B-Instruct\", \"Llama-3.1-8B\", \"Mistral-7B-Instruct\", \"Llama-3.1-70B\", \"Llama-3.1-70B-Instruct\", \"phi-3.5-mini-instruct\"]\n",
    "        \n",
    "config_llm = {'agent1_model': 'Llama-3.1-8B-Instruct',\n",
    "             'agent2_model': './checkpoints/education/llama3-8b-sft',\n",
    "             'eval_model': 'Llama-3.1-70B-Instruct',\n",
    "             'iterations': 10,\n",
    "             'verbose': False,\n",
    "             'write': True,\n",
    "             'fp8': True,\n",
    "             'convo_length_limit': 10,\n",
    "             'max_tokens': 256,\n",
    "             'gpus': 1,\n",
    "             'seed': 0,\n",
    "             'task_name': 'Education',\n",
    "             'model_dir': \"./models\"}\n",
    "\n",
    "with open(\"education/Llama-3.1-8B-Instruct.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(config_llm, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_role_prefix(response, expected_role):\n",
    "    \"\"\"\n",
    "    Removes repeated instances of the expected_role prefix at the start (e.g., 'Therapist: Therapist:'),\n",
    "    and ensures the response begins with a single correct expected_role prefix.\n",
    "    \"\"\"\n",
    "    pattern = rf\"^(({re.escape(expected_role)}):\\s*)+\"\n",
    "    cleaned = re.sub(pattern, '', response.strip(), flags=re.IGNORECASE)\n",
    "    return cleaned\n",
    "    \n",
    "def is_role_confused(response, other_role):\n",
    "    \"\"\"\n",
    "    Checks if the output starts with the wrong speaker tag.\n",
    "    \"\"\"\n",
    "    if other_role + \":\" in response:\n",
    "        return True\n",
    "    else: \n",
    "        return False\n",
    "\n",
    "def generate_response(agent_model, expected_role, other_role, config_llm, prompt, max_retries=10):\n",
    "    count_retries = 0 \n",
    "    role_confused = True\n",
    "    while count_retries<max_retries:\n",
    "        response = completion_create(agent_model, config_llm, prompt)\n",
    "        print(\"Expected Role\", expected_role)\n",
    "        role_confused = is_role_confused(response, other_role)\n",
    "        count_retries+=1\n",
    "        if not is_role_confused(response, other_role):\n",
    "            return clean_role_prefix(response, expected_role)\n",
    "            \n",
    "    return clean_role_prefix(response, expected_role)\n",
    "\n",
    "def generate_conversation(config_llm, p1, p2, p1_name, p2_name, subject, role, pturn=1):\n",
    "    stats['P1'] = p1\n",
    "    stats['P2'] = p2\n",
    "    stats[\"topic\"] = subject\n",
    "    stats[\"grade\"] = role\n",
    "    stats['pturn'] = pturn\n",
    "    round_num = 0\n",
    "    while round_num < config_llm['convo_length_limit']:\n",
    "        conversation = (\"\".join([turn[1] if isinstance(turn, tuple) else turn for turn in stats[\"conversation\"]]) if len(stats[\"conversation\"]) != 0 else \"You are starting the conversation.\\n\")\n",
    "\n",
    "        if pturn == 1:\n",
    "            prompt = config_role[\"agent1_prompt\"]\n",
    "            pturn = 2\n",
    "            if config_llm[\"verbose\"]:\n",
    "                print(prompt)\n",
    "                print()\n",
    "\n",
    "            if round_num!=0: \n",
    "                prompt+= \"Your conversation with the student so far is below:\\nConversation:\\n%CONVERSATION%\"\n",
    "                \n",
    "            if round_num >=config_llm['convo_length_limit']*2-11 and round_num<=config_llm['convo_length_limit']*2-1:\n",
    "                prompt+= \"You have \" + str((config_llm['convo_length_limit']-round_num)//2) + \" rounds left.\" + \"Make sure to conclude the conversation as your near the end.\"\n",
    "\n",
    "            elif round_num>config_llm['convo_length_limit']*2-1:\n",
    "                prompt+= \"This is your concluding line in the conversation.\"\n",
    "\n",
    "            if round_num!=0: \n",
    "                prompt+= \"Continue the conversation with the student. Remember you are the teacher. \"\n",
    "                \n",
    "            prompt += config_role[\"reminder_prompt\"]\n",
    "            prompt+=\"%SPEAKER_ROLE%:\"\n",
    "            prompt = prompt.replace(\"%SPEAKER_ROLE%\", config_role[\"agent1_role\"]) \\\n",
    "                   .replace(\"%LISTENER_ROLE%\", config_role[\"agent2_role\"]) \\\n",
    "                    .replace(\"%ROLE%\", role) \\\n",
    "                   .replace(\"%SUBJECT%\", subject) \\\n",
    "                   .replace(\"%CONVERSATION%\", conversation)\n",
    "            \n",
    "            response = generate_response(config_llm['agent1_model'], config_role[\"agent1_role\"], config_role[\"agent2_role\"], config_llm, prompt)\n",
    "            stats[\"conversation\"].append((round_num, f\"{config_role[\"agent1_role\"]}: \" + response + \"\\n\"))\n",
    "        \n",
    "        else:\n",
    "            prompt = config_role[\"agent2_prompt\"]\n",
    "            pturn = 1    \n",
    "            if config_llm[\"verbose\"]:\n",
    "                print(prompt)\n",
    "                print()\n",
    "\n",
    "            if round_num!=0: \n",
    "                prompt+= \"Your conversation with the teacher so far is below:\\nConversation:\\n%CONVERSATION%\"\n",
    "            if round_num >=config_llm['convo_length_limit']*2-11 and round_num<=config_llm['convo_length_limit']*2-1:\n",
    "                prompt+= \"You have \" + str((config_llm['convo_length_limit']-round_num)//2) + \" rounds left.\" + \"Make sure to conclude the conversation as your near the end.\"\n",
    "            elif round_num>config_llm['convo_length_limit']*2-1:\n",
    "                prompt+= \"This is your concluding line in the conversation.\"\n",
    "\n",
    "            if round_num!=0: \n",
    "                prompt+= \"Continue the conversation with the teacher. Remember you are the student. \"\n",
    "\n",
    "            prompt += config_role[\"reminder_prompt\"]\n",
    "            \n",
    "            prompt+=\"%SPEAKER_ROLE%:\"\n",
    "            prompt = prompt.replace(\"%SPEAKER_ROLE%\", config_role[\"agent2_role\"]) \\\n",
    "               .replace(\"%LISTENER_ROLE%\", config_role[\"agent1_role\"]) \\\n",
    "               .replace(\"%SPEAKER_BACKSTORY%\", p2) \\\n",
    "                .replace(\"%ROLE%\", role) \\\n",
    "               .replace(\"%SUBJECT%\", subject) \\\n",
    "               .replace(\"%CONVERSATION%\", conversation)\n",
    "            \n",
    "            response = generate_response(config_llm['agent2_model'], config_role[\"agent2_role\"], config_role[\"agent1_role\"], config_llm, prompt)\n",
    "            stats[\"conversation\"].append((round_num, f\"{config_role[\"agent2_role\"]}: \" + response + \"\\n\"))\n",
    "            \n",
    "        round_num += 1\n",
    "\n",
    "    stats[\"rounds\"] = round_num\n",
    "    if config_llm['verbose']:\n",
    "        print(stats[\"conversation\"])\n",
    "    return stats.copy()\n",
    "\n",
    "def reset_stats():\n",
    "    stats_template = {\n",
    "        \"task_name\": config_llm['task_name'],\n",
    "        \"topic\": \"\",\n",
    "        \"grade\": \"\",\n",
    "        \"P1\": \"\",\n",
    "        \"P2\": \"\",\n",
    "        \"conversation\": [],\n",
    "        \"pturn\": 0, # beginning person (1 or 2)\n",
    "        \"index\": -1,\n",
    "        \"timestamp\": \"\",\n",
    "        \"rounds\": 0,\n",
    "        'conversation_only': True\n",
    "    }\n",
    "    for key, value in stats_template.items():\n",
    "        stats[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "import utils\n",
    "utils.config = config_llm\n",
    "\n",
    "current_date = str(datetime.now().strftime(\"%m.%d.%y\"))\n",
    "output_dir = f\"education/exp/{current_date}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate unique random number for filename\n",
    "def generate_unique_file_number(output_dir, prefix, seed, extension=\".json\"):\n",
    "    while True:\n",
    "        rand_num = random.randint(0, 1000)\n",
    "        filename = f\"{prefix}_{seed}_{rand_num}{extension}\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        if not os.path.exists(filepath):\n",
    "            return rand_num\n",
    "\n",
    "unique_num = generate_unique_file_number(\n",
    "    output_dir,\n",
    "    config_llm['agent1_model'],\n",
    "    config_llm['seed']\n",
    ")\n",
    "\n",
    "# File to write output to\n",
    "write_file = os.path.join(output_dir, f\"sft_{config_llm['agent1_model']}_{config_llm['seed']}_{unique_num}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# 1. Build a “persona pool” of length 100\n",
    "pool = personas * (100 // len(personas)) \\\n",
    "     + random.sample(personas, 100 % len(personas))\n",
    "random.shuffle(pool)\n",
    "\n",
    "# 2. Sample 100 topics *with* replacement\n",
    "topic_choices = random.choices(topic_list, k=100)\n",
    "\n",
    "# 3. Zip them into 100 pairs\n",
    "persona_final = list(zip(topic_choices, pool))\n",
    "assert len(persona_final) == 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"education/config_education_personas.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(persona_final, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompts = {\n",
    "    \"strategy_consistency\": \"%SCENARIO_DESC% Evaluate whether the following line spoken by %SPEAKER_ROLE% contradicts their background. First, describe the interpreted intention of the statement, and whether or not it aligns with the given background of %SPEAKER_ROLE%. Then, provide 1 sentence explaining your reasoning based on the strategy, followed by YES if the line contradicts the given background of %SPEAKER_ROLE%, and NO if it is consistent with the provided background of %SPEAKER_ROLE%. %SPEAKER_ROLE%'s strategy is described as follows:\\n%SPEAKER_STRATEGY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide 1 sentence of reasoning followed by YES or NO.\\n\\n\",\n",
    "    \"background_consistency\": \"%SCENARIO_DESC% Evaluate whether the following line spoken by %SPEAKER_ROLE% contradicts their background. Provide 1 sentence explaining your reasoning based on the background, followed by YES if the line contradicts the given background of %SPEAKER_ROLE%, and NO if it is consistent with the provided background of %SPEAKER_ROLE%. %SPEAKER_ROLE%'s background is described as follows:\\n%SPEAKER_BACKSTORY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide 1 sentence of reason reasoning followed by YES or NO.\\n\\n\",\n",
    "    \"combined_prompt_consistency\": \"%SCENARIO_DESC% Evaluate the intention behind the following line spoken by %SPEAKER_ROLE% and determine whether it contradicts their background. First, describe the interpreted intention of the statement, and whether or not it aligns with the given background of %SPEAKER_ROLE%. Then, answer YES if the line contradicts the given background of %SPEAKER_ROLE% or the intention does not align with the provided background, and answer NO if it does align with the provided background or the intention aligns with the background of %SPEAKER_ROLE%. %SPEAKER_ROLE%'s background is described as follows:\\n%SPEAKER_BACKSTORY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide your answer as 1 sentence explaining your reasoning based on the background and the interpreted intention, followed by YES or NO.\\n\\n\",\n",
    "    \n",
    "    \"forwards_combined_prompt_consistency\": \"%SCENARIO_DESC% Evaluate the intention behind the following line spoken by %SPEAKER_ROLE% and determine whether it contradicts their background. Answer YES if the line contradicts the given background of %SPEAKER_ROLE% or the intention does not align with the provided background, and answer NO if it does align with the provided background or the intention aligns with the background of %SPEAKER_ROLE%, then describe the interpreted intention of the statement and whether or not it aligns with the given background of %SPEAKER_ROLE% within 1 sentence. %SPEAKER_ROLE%'s background is described as follows:\\n%SPEAKER_BACKSTORY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide your answer as YES or NO first, followed by 1 sentence explaining your reasoning based on the background and the interpreted intention.\\n\\n\",\n",
    "    \n",
    "    \"index_consistency\":\"%SCENARIO_DESC% For the following line spoken by %SPEAKER_ROLE%, first determine if there is a CLEAR conflict or inconsistency between the line and any line within the conversation history spoken by %SPEAKER_ROLE%. IF there is a conflict, provide a sentence of reasoning followed by a list of indices of lines in the conversation history that have a clear conflict with the current line. Otherwise, provide a sentence of reasoning followed by an empty list. ONLY INCLUDE INDICES OF LINES THAT CORRESPOND TO %SPEAKER_ROLE%. The conversation up to this point is as follows: %CONVERSATION%. %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide your reasoning as 1 sentence, followed by a list of indices of conflicting lines from the conversation history formatted like a Python list in the following format: [index1, index2, index3, ...].\\n\\n\",\n",
    "    \n",
    "    \"pairwise_consistency\":\"%SCENARIO_DESC% For the following line spoken by %SPEAKER_ROLE%, answer YES if the line directly contradicts the provided line spoken by %LISTENER_ROLE%, and answer NO if the line does not contradict the provided line spoken by %LISTENER_ROLE%. %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n %LISTENER_ROLE% spoke the following line: \\n%LISTENER_LINE%\\n\\n Answer YES if the line spoken by %SPEAKER_ROLE% contradicts the provided line spoken by %LISTENER_ROLE%, and answer NO if the line does not contradict the provided line spoken by %LISTENER_ROLE%, followed by 1 sentence of reasoning.\\n\\n\",\n",
    "\n",
    "    \"backstory_test\": \"Based on the following background, generate a new fact-based multiple choice question with 5 choices addressed directly IN SECOND PERSON, along with its correct answer. Preface the question with 'Question:' and the answer with 'Answer:'.\\n%SPEAKER_BACKSTORY%\\n%PREVIOUS_QUESTIONS%\",\n",
    "    \"answer_backstory\": \"You are %SPEAKER_ROLE%, and you are having a conversation with %LISTENER_ROLE%. Your background is:\\n%SPEAKER_BACKSTORY%\\n So far, the conversation is as below:\\n%CONVERSATION%\\n\\n Based on your conversation above so far, answer the following multiple choice question.\\n%BACKSTORY_QUESTION%\\n\",\n",
    "    \"grade_backstory\": \"As part of grading a test, determine whether the given answer %GIVEN_ANSWER% matches the following correct answer. Respond with either YES or NO.\\nCorrect Answer: %CORRECT_ANSWER%\\n\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(persona_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import consistency_eval\n",
    "consistency_eval.prompts = config_role\n",
    "consistency_eval.config = config_llm\n",
    "consistency_eval.eval_prompts = eval_prompts\n",
    "index_offset = load_stats_file(write_file)\n",
    "conversations = []    \n",
    "lengths = [10, 20, 40, 60]\n",
    "# lengths = [40]\n",
    "count = 0 \n",
    "for i in range(1):\n",
    "    for topic, persona_item in persona_final[:10]:\n",
    "        count+=1\n",
    "        print(count)\n",
    "        background = persona_item[\"description\"]\n",
    "        grade = persona_item[\"grade_level\"]\n",
    "        for convo_length in lengths:\n",
    "            config_llm['convo_length_limit'] = convo_length\n",
    "            reset_stats()\n",
    "            conversation = generate_conversation(\n",
    "                config_llm,\n",
    "                \"\", \n",
    "                background, \n",
    "                \"Teacher\", \n",
    "                \"Student\", \n",
    "                topic, \n",
    "                grade, \n",
    "                pturn=1\n",
    "            )\n",
    "\n",
    "            # conversation_eval = consistency_eval.eval_prompt_consistency(conversation, agents=(2,))\n",
    "            # conversation_eval = consistency_eval.eval_index_consistency(conversation_eval, agents=(2,))\n",
    "            print(conversation)\n",
    "            # print(conversation_eval)\n",
    "            # conversations.append(conversation_eval)\n",
    "            stats['index'] = index_offset\n",
    "            stats['timestamp'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            write_stats(write_file)\n",
    "            index_offset += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_stats(write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"education/exp/04.30.25/mistral-instruct_len_40.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(conversations, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "# 1. Load dialogues and the single consistency score from JSON files for each model\n",
    "model_files = {\n",
    "    \"ModelA\": \"modelA_conversations.json\",\n",
    "    \"ModelB\": \"modelB_conversations.json\",\n",
    "    \"ModelC\": \"modelC_conversations.json\"\n",
    "}\n",
    "\n",
    "dfs = []\n",
    "for model_name, filepath in model_files.items():\n",
    "    with open(filepath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    records = []\n",
    "    for entry in data:\n",
    "        # Adjust field name if needed to match your JSON key\n",
    "        score = entry.get(\"P2_prompt_consistency_score\", entry.get(\"consistency_score\"))\n",
    "        records.append({\n",
    "            \"persona\": entry[\"P2\"],\n",
    "            \"consistency_score\": score,\n",
    "            \"model\": model_name\n",
    "        })\n",
    "    dfs.append(pd.DataFrame(records))\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# 2. Merge with persona metadata to attach grade levels\n",
    "# Assumes a personas.json file: [{\"grade_level\":..., \"description\":...}, ...]\n",
    "with open(\"personas.json\", \"r\") as f:\n",
    "    personas_meta = json.load(f)\n",
    "meta_df = pd.DataFrame(personas_meta).rename(columns={\"description\": \"persona\"})\n",
    "df = df.merge(meta_df, on=\"persona\", how=\"left\")\n",
    "\n",
    "# 3. Boxplot: consistency distribution by model\n",
    "plt.figure()\n",
    "df.boxplot(column=\"consistency_score\", by=\"model\")\n",
    "plt.title(\"Consistency Score Distribution by Model\")\n",
    "plt.suptitle(\"\")\n",
    "plt.ylabel(\"Consistency Score\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.show()\n",
    "\n",
    "# 4. Heatmap: mean consistency per persona and model\n",
    "pivot = df.pivot_table(\n",
    "    index=\"persona\", columns=\"model\", values=\"consistency_score\", aggfunc=\"mean\"\n",
    ")\n",
    "plt.figure()\n",
    "plt.imshow(pivot.values, aspect='auto', interpolation='none')\n",
    "plt.xticks(ticks=np.arange(len(pivot.columns)), labels=pivot.columns, rotation=45, ha='right')\n",
    "plt.yticks(ticks=np.arange(len(pivot.index)), labels=pivot.index)\n",
    "plt.colorbar(label=\"Mean Consistency\")\n",
    "plt.title(\"Mean Consistency Heatmap (Persona × Model)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Bar chart: average consistency by grade level for each model\n",
    "grade_means = df.groupby([\"grade_level\", \"model\"])[\"consistency_score\"].mean().unstack()\n",
    "plt.figure()\n",
    "grade_means.plot(kind=\"bar\")\n",
    "plt.title(\"Average Consistency by Grade Level and Model\")\n",
    "plt.ylabel(\"Mean Consistency Score\")\n",
    "plt.xlabel(\"Grade Level\")\n",
    "plt.legend(title=\"Model\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Dendrogram: cluster personas by their consistency profile across models\n",
    "# Create matrix: rows=persona, cols=models\n",
    "profile = df.pivot_table(\n",
    "    index=\"persona\", columns=\"model\", values=\"consistency_score\", aggfunc=\"mean\"\n",
    ")\n",
    "Z = sch.linkage(profile.values, method='average', metric='euclidean')\n",
    "plt.figure(figsize=(10, 5))\n",
    "sch.dendrogram(Z, labels=profile.index, leaf_rotation=90)\n",
    "plt.title(\"Dendrogram of Personas by Consistency Profile\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openrlhf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
